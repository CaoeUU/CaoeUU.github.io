<!DOCTYPE html>
<html lang="en-us">
  <head>
    
    <script type="application/ld+json">

{
  "@context": "https://schema.org",
  "@type": "BlogPosting",
  "headline": "Simple Insights About Transformer Model",
  
  "datePublished": "2024-03-12T16:12:50+08:00",
  "dateModified": "2024-03-12T16:12:50+08:00",
  "author": {
    "@type": "Person",
    "name": "Xiaocao You",
    
    "image": "https://xiaocao.me/images/caosmile.jpg"
    
  },
  "mainEntityOfPage": { 
    "@type": "WebPage",
    "@id": "https:\/\/xiaocao.me\/posts\/simple-insights-about-transformer-model\/" 
  },
  "publisher": {
    "@type": "Organization",
    "name": "Tiny Grassland",
    
    "logo": {
      "@type": "ImageObject",
      "url": "https://xiaocao.me/images/caosmile.jpg"
    }
    
  },
  "description": " This is a brief introduction to transformer that simplifies the model\u0026rsquo;s structure to help build a quick understanding of what it is trying to realize. The original blogs and video where I learned about it have been posted below.\n",
  "keywords": []
}

</script>
    <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="generator" content="Hugo 0.125.6 with theme Tranquilpeak 0.5.3-BETA">
<meta name="author" content="Xiaocao You">
<meta name="keywords" content="">
<meta name="description" content="
This is a brief introduction to transformer that simplifies the model&rsquo;s structure to help build a quick understanding of what it is trying to realize. The original blogs and video where I learned about it have been posted below.
">


<meta property="og:description" content="
This is a brief introduction to transformer that simplifies the model&rsquo;s structure to help build a quick understanding of what it is trying to realize. The original blogs and video where I learned about it have been posted below.
">
<meta property="og:type" content="article">
<meta property="og:title" content="Simple Insights About Transformer Model">
<meta name="twitter:title" content="Simple Insights About Transformer Model">
<meta property="og:url" content="https://xiaocao.me/posts/simple-insights-about-transformer-model/">
<meta property="twitter:url" content="https://xiaocao.me/posts/simple-insights-about-transformer-model/">
<meta property="og:site_name" content="Tiny Grassland">
<meta property="og:description" content="
This is a brief introduction to transformer that simplifies the model&rsquo;s structure to help build a quick understanding of what it is trying to realize. The original blogs and video where I learned about it have been posted below.
">
<meta name="twitter:description" content="
This is a brief introduction to transformer that simplifies the model&rsquo;s structure to help build a quick understanding of what it is trying to realize. The original blogs and video where I learned about it have been posted below.
">
<meta property="og:locale" content="en-us">

  
    <meta property="article:published_time" content="2024-03-12T16:12:50">
  
  
    <meta property="article:modified_time" content="2024-03-12T16:12:50">
  
  
  
  
    
      <meta property="article:tag" content="NLP">
    
  


<meta name="twitter:card" content="summary">







  <meta property="og:image" content="https://xiaocao.me/images/caosmile.jpg">
  <meta property="twitter:image" content="https://xiaocao.me/images/caosmile.jpg">






    <title>Simple Insights About Transformer Model</title>

    <link rel="icon" href="https://xiaocao.me/favicon.png">
    

    

    <link rel="canonical" href="https://xiaocao.me/posts/simple-insights-about-transformer-model/">

    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.3/css/all.min.css" integrity="sha512-iBBXm8fW90+nuLcSKlbmrPcLa0OT92xO1BIsZ+ywDWZCvqsWgccV3gFoRBv0z+8dLJgyAHIhR35VZc2oM/gI1w==" crossorigin="anonymous" referrerpolicy="no-referrer" />
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css" integrity="sha512-H9jrZiiopUdsLpg94A333EfumgUBpO9MdbxStdeITo+KEIMaNfHNvwyjjDJb+ERPaRS6DpyRlKbvPUasNItRyw==" crossorigin="anonymous" referrerpolicy="no-referrer" />
    
    
    
    <link rel="stylesheet" href="https://xiaocao.me/css/style-h6ccsoet3mzkbb0wngshlfbaweimexgqcxj0h5hu4h82olsdzz6wmqdkajm.min.css" />
    
    

    
  



    
  </head>

  <body>
    <div id="blog">
      <header id="header" data-behavior="1">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="https://xiaocao.me/" aria-label="">Tiny Grassland</a>
  </div>
  
</header>

      <nav id="sidebar" data-behavior="1">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <a href="https://xiaocao.me/#about" aria-label="">
          <img class="sidebar-profile-picture" src="https://xiaocao.me/images/caosmile.jpg" alt="" />
        </a>
        <h4 class="sidebar-profile-name">Xiaocao You</h4>
        
          <h5 class="sidebar-profile-bio">A Junior Student Majored in Statistics in Shanghai University of Finance and Economics</h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://xiaocao.me/" title="Home">
    
      <i class="sidebar-button-icon fas fa-lg fa-home" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">Home</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://xiaocao.me/posts/" title="Posts">
    
      <i class="sidebar-button-icon fas fa-lg fa-book" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">Posts</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://xiaocao.me/about" title="About">
    
      <i class="sidebar-button-icon fas fa-lg fa-question" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">About</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://github.com/CaoeUU" target="_blank" rel="noopener" title="GitHub">
    
      <i class="sidebar-button-icon fab fa-lg fa-github" aria-hidden="true"></i>
      
      <span class="sidebar-button-desc">GitHub</span>
    </a>
  </li>


    </ul>
    <ul class="sidebar-buttons">
      

    </ul>
  </div>
</nav>

      

      <div id="main" data-behavior="1"
        class="
               hasCoverMetaIn
               ">
        <article class="post" id="top">
          
          
            <div class="post-header main-content-wrap text-left">
  
    <h1 class="post-title">
      Simple Insights About Transformer Model
    </h1>
  
  
  <div class="postShorten-meta post-meta">
    
      <time datetime="2024-03-12T16:12:50&#43;08:00">
        
   12, 2024

      </time>
    
    
  </div>

</div>
          
          <div class="post-content markdown">
            <div class="main-content-wrap">
              <blockquote>
<p>This is a brief introduction to transformer that simplifies the model&rsquo;s structure to help build a quick understanding of what it is trying to realize. The original blogs and video where I learned about it have been posted below.</p>
</blockquote>
<h3 id="links-to-the-reference">Links to the reference</h3>
<ul>
<li><em><a href="https://jalammar.github.io/illustrated-transformer/">The Illustrated Transformer (A detailed introduction to Transformer)</a></em></li>
<li><em><a href="https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/">Introduction to the Mechanics of Seq2seq Models With Attention</a></em></li>
<li><em><a href="https://www.youtube.com/watch?v=UNmqTiOnRfg">Brief Introduction to RNNs (Recurrent Neural Networks)</a></em></li>
</ul>
<h2 id="quick-overview">Quick Overview</h2>
<p>Transformer is a framework used in <em>Natural Language Processing</em> to help texts translation and generation. Basically, it utilizes a mechanism called <em><strong>Attention</strong></em> and the <em><strong>Recurrent Neural Network</strong></em> to work. Don&rsquo;t hurry to figure out what they are if you are confused about these two terms. I&rsquo;ll give necessary explanation to them when it comes to the concrete process in Transformer.</p>
<h2 id="the-workflow-of-transformer">The Workflow of Transformer</h2>
<p>Let&rsquo;s restrict our explanation under the topics of <em>language translation</em>. In this case, we input a sequence of words (namely sentence) into the transformer model and get the output of a sequence of words in another language.</p>
<p>The entire procedure in the model could be divided into 2 parts: Encoding and Decoding.</p>
<p><img src="https://xiaocao.me/images/transformer-workflow.jpg" alt="Workflow of Transformer"></p>
<h3 id="--encoding">- Encoding</h3>
<h4 id="1-word-embedding">1. <strong>Word Embedding</strong></h4>
<ul>
<li>Transfer the input sequence into numerical vectors.</li>
</ul>
<p>The calculation in the model should be implemented with mathematical methods, so it&rsquo;s a necessity to transfer the natural language into numerical forms.</p>
<h4 id="2-processing-vectors-through-the-encoders">2. <strong>Processing vectors through the encoders</strong></h4>
<ul>
<li>Encode the input sentence with those vectors to capture the meaning of the each single word and the connection between different words.</li>
</ul>
<p>This is the procedure when the computer is trying to percieve the text. Though during the word embedding, the similarities in meaning of words have been considered, in the encoding part, we are trying to grab the link between words in the given sentence.</p>
<p>The method to capture the features is the Attention mechanism and RNNs.</p>
<p><strong>Attention</strong> means when processing a specific word in the input sequence, we generate a vector to denote the influence of each word in the entire sentence on the one being processed. The vectors will be passed to the following decoding process, unveiling how much attention we should pay to other words in the input aside from the one we are trying to decode. So we can simply percieve the Attention as weighted average of the elements in the input sequence.</p>
<p>The way we process the sequence is element by element. However, as we all know the semantic meaning is continous throughout the sequence. The feature of words are expected to generate based on the last words and update considering the following words. So when going through the neural networks, what we need is not only the current word being processed, but also the feature captured of the last word. The neural network that takes both additional information and the output it generated as input is called <strong>recurrent neural network</strong>.</p>
<p>Based on the RNNs with Attention, we get the encoding results of the input sequence. Then we pass it to the next stage decoding.</p>
<h3 id="--decoding">- Decoding</h3>
<h4 id="1-processing-through-the-decoders">1. Processing through the decoders</h4>
<ul>
<li>Decode the result of the Encoding, give the translation of the words in the input sequence to other numerical vectors oriented to the language we want to translate into.</li>
</ul>
<p>As we take advantage of the attention mechanics, when decoding a specific vector, we are able to pay attention to other semantically related words in the intial sequence so that the model could perform better.</p>
<h4 id="2-vocabulary-mapping">2. Vocabulary mapping</h4>
<ul>
<li>Transfer the output numerical vectors in the Decoding into words in the objective language.</li>
</ul>
<p>First we map the output vectors into the vectors that have the same dimensions as the embedded words in the objective language, so that we can calculate the probabilities of word candidates. When training data, we use supervised method to optimize the loss funciton to give a prediction of the translated sentence. So we expect the model to predict the correct words based on the probability it calculates for the mapped vectors.</p>
              


            </div>
          </div>
          <div id="post-footer" class="post-footer main-content-wrap">
            
              
                
                
                  <div class="post-footer-tags">
                    <span class="text-color-light text-small"></span><br/>
                    
  <a class="tag tag--primary tag--small" href="https://xiaocao.me/tags/nlp/">NLP</a>

                  </div>
                
              
            
            
<div class="post-actions-wrap">
  <nav >
    <ul class="post-actions post-action-nav">
      
        <li class="post-action">
          
            <a class="post-action-btn btn btn--default tooltip--top" href="https://xiaocao.me/posts/distributed-computing-notes-1/" data-tooltip="分布式计算整理-1" aria-label=": 分布式计算整理-1">
          
              <i class="fa fa-angle-left"></i>
              <span class="hide-xs hide-sm text-small icon-ml"></span>
            </a>
        </li>
        <li class="post-action">
          
            <a class="post-action-btn btn btn--default tooltip--top" href="https://xiaocao.me/posts/lab-notes-for-cs231n-assignment-1-updating/" data-tooltip="Cs231n Labnotes1" aria-label=": Cs231n Labnotes1">
          
              <span class="hide-xs hide-sm text-small icon-mr"></span>
              <i class="fa fa-angle-right"></i>
            </a>
        </li>
      
    </ul>
  </nav>
<ul class="post-actions post-action-share" >
  
    <li class="post-action hide-lg hide-md hide-sm">
      <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions" aria-label="">
        <i class="fa fa-share-alt" aria-hidden="true"></i>
      </a>
    </li>
    
  
  
  <li class="post-action">
    
      <a class="post-action-btn btn btn--default" href="#top" aria-label="">
      <i class="fa fa-arrow-up" aria-hidden="true"></i>
    
    </a>
  </li>
</ul>
</div>


            
  


          </div>
        </article>
        <footer id="footer" class="main-content-wrap">
  <span class="copyrights">
    &copy; 2024 <a href="https://github.com/CaoeUU">XiaocaoYou</a>. 
  </span>
  <section class="powerby">
    Theme modifided from
    <a href="https://github.com/kakawait/hugo-tranquilpeak-theme" target="_blank" rel="noopener">tranquilpeak</a>
    .Built with 
    <a href="https://gohugo.io/" target="_blank" rel="noopener">Hugo</a>

  </section>
  <script async 
  src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js">
  </script>
  <span id="busuanzi_container_site_uv">
    Total views: <span id="busuanzi_value_site_uv"></span>
  </span>
</footer>
<script type="text/javascript"
  src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
      </div>
      <div id="bottom-bar" class="post-bottom-bar" data-behavior="1">
        
<div class="post-actions-wrap">
  <nav >
    <ul class="post-actions post-action-nav">
      
        <li class="post-action">
          
            <a class="post-action-btn btn btn--default tooltip--top" href="https://xiaocao.me/posts/distributed-computing-notes-1/" data-tooltip="分布式计算整理-1" aria-label=": 分布式计算整理-1">
          
              <i class="fa fa-angle-left"></i>
              <span class="hide-xs hide-sm text-small icon-ml"></span>
            </a>
        </li>
        <li class="post-action">
          
            <a class="post-action-btn btn btn--default tooltip--top" href="https://xiaocao.me/posts/lab-notes-for-cs231n-assignment-1-updating/" data-tooltip="Cs231n Labnotes1" aria-label=": Cs231n Labnotes1">
          
              <span class="hide-xs hide-sm text-small icon-mr"></span>
              <i class="fa fa-angle-right"></i>
            </a>
        </li>
      
    </ul>
  </nav>
<ul class="post-actions post-action-share" >
  
    <li class="post-action hide-lg hide-md hide-sm">
      <a class="post-action-btn btn btn--default btn-open-shareoptions" href="#btn-open-shareoptions" aria-label="">
        <i class="fa fa-share-alt" aria-hidden="true"></i>
      </a>
    </li>
    
  
  
  <li class="post-action">
    
      <a class="post-action-btn btn btn--default" href="#top" aria-label="">
      <i class="fa fa-arrow-up" aria-hidden="true"></i>
    
    </a>
  </li>
</ul>
</div>


      </div>
      

    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-times"></i>
    </div>
    
      <img id="about-card-picture" src="https://xiaocao.me/images/caosmile.jpg" alt="" />
    
    <h4 id="about-card-name">Xiaocao You</h4>
    
      <div id="about-card-bio">A Junior Student Majored in Statistics in Shanghai University of Finance and Economics</div>
    
    
    
      <div id="about-card-location">
        <i class="fa fa-map-marker-alt"></i>
        <br/>
        Shanghai, China
      </div>
    
  </div>
</div>

    

    
  
    
      <div id="cover" style="background-image:url('https://xiaocao.me/images/background.jpg');"></div>
    
  


    
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" integrity="sha512-894YE6QWD5I59HgZOGReFYm4dnWc1Qt5NtvYSaNcOP+u1T9qYdvdihz0PPSiiqn/+/3e7Jo4EaG7TubfWGUrMQ==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>

<script src="https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js" integrity="sha512-uURl+ZXMBrF4AwGaWmEetzrd+J5/8NRkWAvJx5sbPSSuOb0bZLqf+tOzniObO00BjHa/dD7gub9oCGMLPQHtQA==" crossorigin="anonymous" referrerpolicy="no-referrer"></script>


<script src="https://xiaocao.me/js/script-yqzy9wdlzix4lbbwdnzvwx3egsne77earqmn73v9uno8aupuph8wfguccut.min.js"></script>






    
  </body>
</html>

